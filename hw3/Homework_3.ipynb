{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258, Fall 2019: Homework 3\n",
    "**You’ll probably want to implement your solution by modifying the baseline code provided.**   \n",
    "Files: \n",
    "* http://cseweb.ucsd.edu/classes/fa19/cse258-a/files/assignment1.tar.gz   \n",
    "\n",
    "Kaggle:\n",
    "* https://inclass.kaggle.com/c/cse158258-fa19-read-prediction\n",
    "* (258 only) https://inclass.kaggle.com/c/cse258-fa19-rating-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (Read prediction)   \n",
    "Since we don’t have access to the test labels, we’ll need to simulate validation/test sets of our own.    \n",
    "So, let’s split the training data (‘train Interactions.csv.gz’) as follows:\n",
    "1. Reviews 1-190,000 for training\n",
    "2. Reviews 190,001-200,000 for validation\n",
    "3. Upload to Kaggle for testing only when you have a good model on the validation set. This will save you time (since Kaggle can take several minutes to return results), and prevent you from exceeding your daily submission limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "    \n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    header = f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [line[:2] + [1] for line in readCSV(\"train_Interactions.csv.gz\")] # 1 is the label saying it is read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Although we have built a validation set, it only consists of positive samples. For this task we also need examples of user/item pairs that weren’t read. For each entry (user,book) in the validation set, sample a negative entry by randomly choosing a book that user hasn’t read. Evaluate the performance (accuracy) of the baseline model on the validation set you have built (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = data[:190000]\n",
    "Xy_valid = data[190000:]\n",
    "# First get overview of what books each user have read, and what what user a book has been read by.\n",
    "usersPerBook = defaultdict(set)\n",
    "bookPerUser = defaultdict(set)\n",
    "for line in data:\n",
    "    userID, bookID, rating = line\n",
    "    usersPerBook[bookID].add(userID)\n",
    "    bookPerUser[userID].add(bookID)\n",
    "\n",
    "# Randomly ad some negative samples to the validation set\n",
    "negative_samples = []\n",
    "available_books = usersPerBook.keys()\n",
    "for user, book, has_read in Xy_valid:\n",
    "    #print(user,book)\n",
    "    random_book = random.choice(list(available_books))\n",
    "    while random_book in bookPerUser[user]:\n",
    "        random_book = random.choice(list(available_books))\n",
    "    new_data = [user, random_book, 0]\n",
    "    negative_samples.append(new_data)\n",
    "Xy_valid += negative_samples # Add the negative data\n",
    "random.shuffle(Xy_valid)\n",
    "\n",
    "Xtrain, ytrain = [d[:2] for d in Xy_train], [d[2] for d in Xy_train]\n",
    "Xvalid, yvalid = [d[:2] for d in Xy_valid], [d[2] for d in Xy_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    predictions, labels = np.array(predictions), np.array(labels)\n",
    "    return sum(predictions == labels) / len(predictions)\n",
    "\n",
    "def most_popular_percentile(mostPopular, percentile):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for b_count, b in mostPopular:\n",
    "        count += b_count\n",
    "        return1.add(b)\n",
    "        if count > percentile * totalRead: break\n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6464\n"
     ]
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book in Xtrain:\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort(reverse=True)\n",
    "\n",
    "return1 = most_popular_percentile(mostPopular, 0.5)\n",
    "\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    pred = 1 if book in return1 else 0\n",
    "    predictions.append(pred)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "The existing ‘read prediction’ baseline just returns True if the item in question is ‘popular,’ using a threshold of the 50th percentile of popularity (totalRead/2). Assuming that the ‘non-read’ test examples are a random sample of user-book pairs, this threshold may not be the best one. See if you can find a better threshold and report its performance on your validatin set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "thresholds = np.arange(0.05, 1.0, 0.05)\n",
    "scores = []\n",
    "for th in thresholds:\n",
    "    return1 = most_popular_percentile(mostPopular, th)\n",
    "    predictions = []\n",
    "    for user, book in Xvalid:\n",
    "        pred = 1 if book in return1 else 0\n",
    "        predictions.append(pred)\n",
    "\n",
    "    scores.append(accuracy(predictions, yvalid))\n",
    "scores = [100*x for x in scores]\n",
    "plt.plot(thresholds*100, scores)\n",
    "plt.xlabel(\"Percentile (%)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds*100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can see that it gets the highest accuracy by setting the percentile to 55% instead of 50%. So we use that, and we get an accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6542\n"
     ]
    }
   ],
   "source": [
    "return1 = most_popular_percentile(mostPopular, 0.55)\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    pred = 1 if book in return1 else 0\n",
    "    predictions.append(pred)\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is only about 0.05 % better performance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "A stronger baseline than the one provided might make use of the Jaccard similarity (or another similarity\n",
    "metric). Given a pair (u, b) in the validation set, consider all training items b′ that user u has read. For each, compute the Jaccard similarity between b and b′, i.e., users (in the training set) who have read ′\n",
    "b and users who have read b . Predict as ‘read’ if the maximum of these Jaccard similarities exceeds a threshold (you may choose the threshold that works best). Report the performance on your validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the training data into other datastructures\n",
    "usersPerBook = defaultdict(set)\n",
    "bookPerUser = defaultdict(set)\n",
    "for user, book in Xtrain:\n",
    "    usersPerBook[book].add(user)\n",
    "    bookPerUser[user].add(book)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Predict by using the Jaccard sim and a threshold\n",
    "def predict(user, book, threshold=0.03):\n",
    "    similarities = []\n",
    "    users = usersPerBook[book]\n",
    "\n",
    "    # More efficient by considering a smaller candidate set of items.\n",
    "    # We restrict the search to only those items that could possibly have non-zero Jaccard sim.\n",
    "    candidateItems = set() \n",
    "    for u in users:\n",
    "        candidateItems = candidateItems.union(bookPerUser[u])\n",
    "\n",
    "    # Compute the similarity between the book to predict and all the books in candidateItems\n",
    "    for book2 in candidateItems:\n",
    "        if book2 == book:\n",
    "            continue\n",
    "        # Simularity between the uservector for book compared to uservector for book2\n",
    "        sim = Jaccard(users, usersPerBook[book2])\n",
    "        similarities.append((sim, book2))\n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    # Predict based on Jaccard sim and popularity\n",
    "    return len(similarities) > 0 and similarities[0][0] > threshold\n",
    "\n",
    "# Make predictions based on Jaccard\n",
    "threshold = 0.15 \n",
    "predictions = []\n",
    "for user, book in Xvalid[:100]:\n",
    "    predictions.append(predict(user, book, thereshold))\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid[:100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Improve the above predictor by incorporating both a Jaccard-based threshold and a popularity based threshold. Report the performance on your validation set (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 100\n",
      "Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict by using the Jaccard sim and the popularity\n",
    "def predict(user, book, popularPercentile, threshold=0.03):\n",
    "    similarities = []\n",
    "    users = usersPerBook[book]\n",
    "\n",
    "    # More efficient by considering a smaller candidate set of items.\n",
    "    # We restrict the search to only those items that could possibly have non-zero Jaccard sim.\n",
    "    candidateItems = set() \n",
    "    for u in users:\n",
    "        candidateItems = candidateItems.union(bookPerUser[u])\n",
    "\n",
    "    # Compute the similarity between the book to predict and all the books in candidateItems\n",
    "    for book2 in candidateItems:\n",
    "        if book2 == book:\n",
    "            continue\n",
    "        # Simularity between the uservector for book compared to uservector for book2\n",
    "        sim = Jaccard(users, usersPerBook[book2])\n",
    "        similarities.append((sim, book2))\n",
    "    similarities.sort(reverse=True)\n",
    "    \n",
    "    # Predict based on Jaccard sim and popularity\n",
    "    #if len(similarities) >0:\n",
    "        #print(similarities[0][0] > threshold, book in popularPercentile)\n",
    "    pred = (len(similarities) > 0) and ((similarities[0][0] > threshold) or (book in popularPercentile))\n",
    "    return int(pred)\n",
    "        \n",
    "popularity_th = 0.70\n",
    "jaccard_th = 0.70\n",
    "\n",
    "popularPercentile = most_popular_percentile(mostPopular, popularity_th)      \n",
    "predictions = []\n",
    "xval, yval = Xvalid[:100], yvalid[:100]\n",
    "for user, book in xval:\n",
    "    predictions.append(predict(user, book, popularPercentile, threshold=jaccard_th))\n",
    "print(sum(predictions), len(predictions))\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global popularity_th\n",
    "    global jaccard_th\n",
    "    popularity_th, jaccard_th = theta\n",
    "    \n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "    \n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [predict(user, book, popularPercentile, threshold=jaccard_th) for user, book in Xvalid[:100]]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(Xvalid[:100])\n",
    "    dpopularity_th = 0\n",
    "    djaccard_th = 0\n",
    "    i = 0\n",
    "    for user, book in Xvalid[:100]:\n",
    "        pred = predict(u, i, popularity_th, jaccard_th)\n",
    "        diff = pred - yvalid[i]\n",
    "        dpopularity_th += 2/N*diff\n",
    "        djaccard_th += 2/N*diff \n",
    "        i+=1 \n",
    "    dpopularity_th += 2*lamb*popularity_th\n",
    "    djaccard_th += 2*lamb*jaccard_th\n",
    "\n",
    "    dtheta = [dpopularity_th, djaccard_th]\n",
    "    print(dtheta)\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 0 0\n",
      "MSE = 0.49\n",
      "[-1.0200000000000005, -1.0200000000000005]\n",
      "MSE = 0.34\n",
      "[0.39421356237309446, 0.39421356237309446]\n",
      "MSE = 0.34\n",
      "[0.0, 0.0]\n",
      "MSE = 0.34\n",
      "[0.2630060007544939, 0.2630060007544939]\n",
      "MSE = 0.34\n",
      "[0.3624163050056466, 0.3624163050056466]\n",
      "MSE = 0.34\n",
      "[0.3872835572243416, 0.3872835572243416]\n",
      "MSE = 0.34\n",
      "[0.39274088131487983, 0.39274088131487983]\n",
      "MSE = 0.34\n",
      "[0.39390231488211924, 0.39390231488211924]\n",
      "MSE = 0.34\n",
      "[0.394147857394646, 0.394147857394646]\n",
      "MSE = 0.34\n",
      "[0.39419969532420485, 0.39419969532420485]\n",
      "MSE = 0.34\n",
      "[0.3942106358813473, 0.3942106358813473]\n",
      "MSE = 0.34\n",
      "[0.3942129447751961, 0.3942129447751961]\n",
      "MSE = 0.34\n",
      "[0.3942134320374173, 0.3942134320374173]\n",
      "MSE = 0.34\n",
      "[0.3942135348675273, 0.3942135348675273]\n",
      "MSE = 0.34\n",
      "[0.39421355656842016, 0.39421355656842016]\n",
      "MSE = 0.34\n",
      "[0.39421356114809725, 0.39421356114809725]\n",
      "MSE = 0.34\n",
      "[0.3942135621145755, 0.3942135621145755]\n",
      "MSE = 0.34\n",
      "[0.39421356231853766, 0.39421356231853766]\n",
      "MSE = 0.34\n",
      "[0.394213562361581, 0.394213562361581]\n",
      "MSE = 0.34\n",
      "[0.3942135623706646, 0.3942135623706646]\n",
      "MSE = 0.34\n",
      "[0.39421356237258176, 0.39421356237258176]\n",
      "MSE = 0.34\n",
      "[0.3942135623729863, 0.3942135623729863]\n",
      "MSE = 0.34\n",
      "[-0.39421356237309446, -0.39421356237309446]\n",
      "MSE = 0.34\n",
      "[0.00039421356237312466, 0.00039421356237312466]\n",
      "MSE = 0.34\n",
      "[0.2632027300514459, 0.2632027300514459]\n",
      "MSE = 0.34\n",
      "[0.3624709103931065, 0.3624709103931065]\n",
      "MSE = 0.34\n",
      "[0.3872958456175821, 0.3872958456175821]\n",
      "MSE = 0.34\n",
      "[0.39274351086050197, 0.39274351086050197]\n",
      "MSE = 0.34\n",
      "[0.3939028714479704, 0.3939028714479704]\n",
      "MSE = 0.34\n",
      "[0.3941479749233401, 0.3941479749233401]\n",
      "MSE = 0.34\n",
      "[0.39419972013028626, 0.39419972013028626]\n",
      "MSE = 0.34\n",
      "[0.39421064111647675, 0.39421064111647675]\n",
      "MSE = 0.34\n",
      "[0.394212945880005, 0.394212945880005]\n",
      "MSE = 0.34\n",
      "[0.3942134322705724, 0.3942134322705724]\n",
      "MSE = 0.34\n",
      "[0.3942135349167315, 0.3942135349167315]\n",
      "MSE = 0.34\n",
      "[0.3942135565788041, 0.3942135565788041]\n",
      "MSE = 0.34\n",
      "[0.3942135611502886, 0.3942135611502886]\n",
      "MSE = 0.34\n",
      "[0.394213562115038, 0.394213562115038]\n",
      "MSE = 0.34\n",
      "[0.39421356231863514, 0.39421356231863514]\n",
      "MSE = 0.34\n",
      "[0.39421356236160165, 0.39421356236160165]\n",
      "MSE = 0.34\n",
      "[0.39421356237066907, 0.39421356237066907]\n",
      "MSE = 0.34\n",
      "[0.39421356237258265, 0.39421356237258265]\n",
      "END 0.7071067811862916 0.7071067811862916\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import scipy\n",
    "popularity_th = 0\n",
    "jaccard_th = 0\n",
    "print(\"START\", popularity_th, jaccard_th)\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [popularity_th, jaccard_th],\n",
    "                             derivative, args = (yvalid[:100], 1))\n",
    "print(\"END\", popularity_th, jaccard_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "To run our model on the test set, we’ll have to use the files ‘pairs Read.txt’ to find the reviewerID/itemID pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you’ve already uploaded a better solution to Kaggle, that’s fine too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularPercentile = most_popular_percentile(mostPopular, popularity_th)   \n",
    "\n",
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    user, book = l.strip().split('-')\n",
    "    pred = predict(user, book, popularPercentile, threshold=jaccard_th)\n",
    "    predictions.write(user + '-' + book + \",{}\\n\".format(pred))\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (CSE 258 only) Tasks (Rating prediction)\n",
    "\n",
    "Let’s start by building our training/validation sets much as we did for the first task. This time building a validation set is more straightforward: you can simply use part of the data for validation, and do not need to randomly sample non-read users/books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "Fit a predictor of the form\n",
    "\n",
    "$rating(user, item) = \\alpha + \\beta_{user} + \\beta_{item}$\n",
    "\n",
    "\n",
    "by fitting the mean and the two bias terms as described in the lecture notes. Use a regularization\n",
    "parameter of λ = 1. Report the MSE on the validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "Report the user and book IDs that have the largest and smallest values of β (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "Find a better value of λ using your validation set. Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
