{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258, Fall 2019: Homework 3\n",
    "**You’ll probably want to implement your solution by modifying the baseline code provided.**   \n",
    "Files: \n",
    "* http://cseweb.ucsd.edu/classes/fa19/cse258-a/files/assignment1.tar.gz   \n",
    "\n",
    "Kaggle:\n",
    "* https://inclass.kaggle.com/c/cse158258-fa19-read-prediction\n",
    "* (258 only) https://inclass.kaggle.com/c/cse258-fa19-rating-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (Read prediction)   \n",
    "Since we don’t have access to the test labels, we’ll need to simulate validation/test sets of our own.    \n",
    "So, let’s split the training data (‘train Interactions.csv.gz’) as follows:\n",
    "1. Reviews 1-190,000 for training\n",
    "2. Reviews 190,001-200,000 for validation\n",
    "3. Upload to Kaggle for testing only when you have a good model on the validation set. This will save you time (since Kaggle can take several minutes to return results), and prevent you from exceeding your daily submission limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "    \n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    header = f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [line[:2] + [1] for line in readCSV(\"train_Interactions.csv.gz\")] # 1 is the label saying it is read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Although we have built a validation set, it only consists of positive samples. For this task we also need examples of user/item pairs that weren’t read. For each entry (user,book) in the validation set, sample a negative entry by randomly choosing a book that user hasn’t read. Evaluate the performance (accuracy) of the baseline model on the validation set you have built (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = data[:190000]\n",
    "Xy_valid = data[190000:]\n",
    "# First get overview of what books each user have read, and what what user a book has been read by.\n",
    "usersPerBook = defaultdict(set)\n",
    "bookPerUser = defaultdict(set)\n",
    "for line in data:\n",
    "    userID, bookID, rating = line\n",
    "    usersPerBook[bookID].add(userID)\n",
    "    bookPerUser[userID].add(bookID)\n",
    "\n",
    "# Randomly ad some negative samples to the validation set\n",
    "negative_samples = []\n",
    "available_books = usersPerBook.keys()\n",
    "for user, book, has_read in Xy_valid:\n",
    "    #print(user,book)\n",
    "    random_book = random.choice(list(available_books))\n",
    "    while random_book in bookPerUser[user]:\n",
    "        random_book = random.choice(list(available_books))\n",
    "    new_data = [user, random_book, 0]\n",
    "    negative_samples.append(new_data)\n",
    "Xy_valid += negative_samples # Add the negative data\n",
    "random.shuffle(Xy_valid)\n",
    "\n",
    "Xtrain, ytrain = [d[:2] for d in Xy_train], [d[2] for d in Xy_train]\n",
    "Xvalid, yvalid = [d[:2] for d in Xy_valid], [d[2] for d in Xy_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    predictions, labels = np.array(predictions), np.array(labels)\n",
    "    return sum(predictions == labels) / len(predictions)\n",
    "\n",
    "def most_popular_percentile(mostPopular, percentile):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for b_count, b in mostPopular:\n",
    "        count += b_count\n",
    "        return1.add(b)\n",
    "        if count > percentile * totalRead: break\n",
    "    return return1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6461\n"
     ]
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book in Xtrain:\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort(reverse=True)\n",
    "\n",
    "return1 = most_popular_percentile(mostPopular, 0.5)\n",
    "\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    pred = 1 if book in return1 else 0\n",
    "    predictions.append(pred)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "The existing ‘read prediction’ baseline just returns True if the item in question is ‘popular,’ using a threshold of the 50th percentile of popularity (totalRead/2). Assuming that the ‘non-read’ test examples are a random sample of user-book pairs, this threshold may not be the best one. See if you can find a better threshold and report its performance on your validatin set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "thresholds = np.arange(0.05, 1.0, 0.05)\n",
    "scores = []\n",
    "for th in thresholds:\n",
    "    return1 = most_popular_percentile(mostPopular, th)\n",
    "    predictions = []\n",
    "    for user, book in Xvalid:\n",
    "        pred = 1 if book in return1 else 0\n",
    "        predictions.append(pred)\n",
    "    scores.append(accuracy(predictions, yvalid))\n",
    "    \n",
    "scores = [100*x for x in scores]\n",
    "plt.plot(thresholds*100, scores)\n",
    "plt.xlabel(\"Percentile (%)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds*100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can see that it gets the highest accuracy by setting the percentile to 55% instead of 50%. So we use that, and we get an accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6525\n"
     ]
    }
   ],
   "source": [
    "return1 = most_popular_percentile(mostPopular, 0.55)\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    pred = 1 if book in return1 else 0\n",
    "    predictions.append(pred)\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "A stronger baseline than the one provided might make use of the Jaccard similarity (or another similarity\n",
    "metric). Given a pair (u, b) in the validation set, consider all training items b′ that user u has read. For each, compute the Jaccard similarity between b and b′, i.e., users (in the training set) who have read ′\n",
    "b and users who have read b . Predict as ‘read’ if the maximum of these Jaccard similarities exceeds a threshold (you may choose the threshold that works best). Report the performance on your validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the training data into other datastructures\n",
    "usersPerBook = defaultdict(set)\n",
    "bookPerUser = defaultdict(set)\n",
    "for user, book in Xtrain:\n",
    "    usersPerBook[book].add(user)\n",
    "    bookPerUser[user].add(book)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6236\n"
     ]
    }
   ],
   "source": [
    "def best_jacc(user, book):\n",
    "    users = usersPerBook[book]\n",
    "    b_mark = bookPerUser[user]\n",
    "    similarities = []\n",
    "    for book2 in b_mark:\n",
    "        if book2 == book:\n",
    "            continue\n",
    "        # compute sim between book and book2\n",
    "        sim = Jaccard(users, usersPerBook[book2])\n",
    "        similarities.append((sim, book2))\n",
    "    similarities.sort(reverse=True)\n",
    "    if len(similarities) == 0:\n",
    "        return 0\n",
    "    return similarities[0][0]\n",
    "\n",
    "# Make predictions based on Jaccard\n",
    "threshold = 0.012\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    best_sim = best_jacc(user, book)\n",
    "    pred = best_sim > threshold\n",
    "    predictions.append(pred)\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Improve the above predictor by incorporating both a Jaccard-based threshold and a popularity based threshold. Report the performance on your validation set (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each book make a featureset [isPopular, Jaccard] and learn use a Classifier from sklearn to learn the params\n",
    "popularity_th = 0.60\n",
    "popularPercentile = most_popular_percentile(mostPopular, popularity_th) \n",
    "\n",
    "# Calculate features for the classifier to find weights\n",
    "def feature(user, book):\n",
    "    popular = 1 if book in popularPercentile else 0\n",
    "    jac_sim = best_jacc(user, book)\n",
    "    return [1,popular,jac_sim]\n",
    "\n",
    "newX = [feature(user, book) for user, book in Xvalid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.78581803,  1.25904501, 15.44709142])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a model that can compute the weights for me\n",
    "model = LogisticRegression(solver=\"lbfgs\", fit_intercept=False)\n",
    "model.fit(newX, yvalid)\n",
    "theta = model.coef_[0]\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8228 20000\n",
      "Accuracy: 0.6575\n"
     ]
    }
   ],
   "source": [
    "# Predict by using the Jaccard sim and the popularity\n",
    "def predict(user, book, theta):\n",
    "    # Weights to be used when predicting\n",
    "    bias, theta_ispop, theta_jacc = theta\n",
    "    \n",
    "    isPopular = int(book in popularPercentile)\n",
    "    jacc_sim = best_jacc(user, book) \n",
    "    pred = bias + theta_ispop*isPopular + theta_jacc*jacc_sim\n",
    "    pred = round(max(0, pred))\n",
    "    #pred = (len(similarities) > 0) and (similarities[0][0] > threshold) and (book in popularPercentile)\n",
    "    return int(pred)\n",
    "        \n",
    "#popularity_th = 0.80\n",
    "#jaccard_th = 0.010\n",
    "\n",
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    predictions.append(predict(user, book, theta))\n",
    "\n",
    "print(sum(predictions), len(predictions))\n",
    "print(\"Accuracy: {}\".format(accuracy(predictions, yvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we dont need the threshold from last task, because the logistic regresser will just scale the importance of my jaccard by it self. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "To run our model on the test set, we’ll have to use the files ‘pairs Read.txt’ to find the reviewerID/itemID pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you’ve already uploaded a better solution to Kaggle, that’s fine too!\n",
    "# Kaggle Username: kristogj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    user, book = l.strip().split('-')\n",
    "    pred = predict(user, book, theta)\n",
    "    predictions.write(user + '-' + book + \",{}\\n\".format(pred))\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (CSE 258 only) Tasks (Rating prediction)\n",
    "\n",
    "Let’s start by building our training/validation sets much as we did for the first task. This time building a validation set is more straightforward: you can simply use part of the data for validation, and do not need to randomly sample non-read users/books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [line for line in readCSV(\"train_Interactions.csv.gz\")]\n",
    "Xy_train, Xy_valid = data[:190000], data[190000:]\n",
    "Xtrain, ytrain = [x[:2] for x in Xy_train], [int(x[-1]) for x in Xy_train]\n",
    "Xvalid, yvalid = [x[:2] for x in Xy_valid], [int(x[-1]) for x in Xy_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "Fit a predictor of the form\n",
    "\n",
    "$rating(user, item) = \\alpha + \\beta_{user} + \\beta_{item}$\n",
    "\n",
    "\n",
    "by fitting the mean and the two bias terms as described in the lecture notes. Use a regularization\n",
    "parameter of λ = 1. Report the MSE on the validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerBook = defaultdict(list)\n",
    "\n",
    "for user, book, rating in Xy_train:\n",
    "    rating = int(rating)\n",
    "    reviewsPerUser[user].append(rating)\n",
    "    reviewsPerBook[book].append(rating)\n",
    "\n",
    "ratingMean = sum(ytrain) / len(ytrain)\n",
    "\n",
    "N = len(ytrain)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nBooks = len(reviewsPerBook)\n",
    "users = list(reviewsPerUser.keys())\n",
    "books = list(reviewsPerBook.keys())\n",
    "\n",
    "lamb = 1\n",
    "alpha = ratingMean\n",
    "userBiases = defaultdict(float)\n",
    "bookBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, book):\n",
    "    return alpha + userBiases[user] + bookBiases[book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global bookBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = defaultdict(float)\n",
    "    bookBiases = defaultdict(float)\n",
    "    for user, t in zip(users, theta[1:nUsers+1]):\n",
    "        userBiases[user] = t\n",
    "    for book, t in zip(books, theta[1+nUsers:]):\n",
    "        bookBiases[book] = t\n",
    "\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(user, book) for user, book in Xtrain]\n",
    "    cost = MSE(predictions, ytrain)\n",
    "    #print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for b in bookBiases:\n",
    "        cost += lamb*bookBiases[b]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dBookBiases = defaultdict(float)\n",
    "    for user, book, rating in Xy_train:\n",
    "        rating = int(rating)\n",
    "        pred = prediction(user, book)\n",
    "        diff = pred - rating\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[user] += 2/N*diff\n",
    "        dBookBiases[book] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[user] += 2*lamb*userBiases[user]\n",
    "    for i in bookBiases:\n",
    "        dBookBiases[book] += 2*lamb*bookBiases[book]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dBookBiases[b] for b in books]\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nBooks),\n",
    "                             derivative, args = (ytrain, lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4907803977377663\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    predictions.append(prediction(user, book))\n",
    "\n",
    "mse = MSE(predictions, yvalid)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "Report the user and book IDs that have the largest and smallest values of β (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Largest user bias: ('u92864068', 0.0004044337058247039) \n",
      " Smallest user bias: ('u11591742', -0.0015810150664586793)\n",
      "\n",
      " Largest book bias: ('b76915592', 0.0008308782940987173) \n",
      " Smallest book bias: ('b57299824', -0.0002723172505094118)\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "userBiases_items = list(userBiases.items())\n",
    "userBiases_items.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n Largest user bias: {} \\n Smallest user bias: {}\".format(userBiases_items[0], userBiases_items[-1]))\n",
    "\n",
    "bookBiases_items = list(bookBiases.items())\n",
    "bookBiases_items.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n Largest book bias: {} \\n Smallest book bias: {}\".format(bookBiases_items[0], bookBiases_items[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "Find a better value of λ using your validation set. Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data (1 mark).\n",
    "# Kaggle Username: kristogj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 0.00002\n",
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nBooks),\n",
    "                             derivative, args = (ytrain, lamb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the right value for lamb by looping over different values of lamb and observing how the mse was chaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1742062925437837\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for user, book in Xvalid:\n",
    "    predictions.append(prediction(user, book))\n",
    "\n",
    "mse = MSE(predictions, yvalid)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    user, book = l.strip().split('-')\n",
    "    pred = str(prediction(user, book))\n",
    "    predictions.write(user + '-' + book + ',' + pred + '\\n')\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
