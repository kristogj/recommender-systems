{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 258, Fall 2019: Homework 2\n",
    "\n",
    "Polish Backruptcy data: https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data\n",
    "\n",
    "## Tasks - Diagnotics (week 2):\n",
    "In the first homework, we had two issues with the classifiers we built. Namely (1) the data were not shuffled, and (2) the labels were highly imbalanced. Both of these made it difficult to effectively build an accurate classifier. Here we’ll try and correct for those issues using the Bankruptcy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 \n",
    "Download and parse the bankruptcy data. We’ll use the 5year.arff file. Code to read the data is available in the stub. Train a logistic regressor (e.g. sklearn.linear model.LogisticRegression) with regularization coefficient C = 1.0. Report the accuracy and Balanced Error Rate (BER) of your classifier (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/5year.arff\", 'r')\n",
    "\n",
    "# Reading in data - removing the first rows with attribute info\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n",
    "# Data setup\n",
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth(X, y, model):\n",
    "    pred = model.predict(X)\n",
    "    correct = pred == y\n",
    "    # True positives, false positives, etc.\n",
    "    TP_ = np.logical_and(pred, y)\n",
    "    FP_ = np.logical_and(pred, np.logical_not(y))\n",
    "    TN_ = np.logical_and(np.logical_not(pred), np.logical_not(y))\n",
    "    FN_ = np.logical_and(np.logical_not(pred), y)\n",
    "    return sum(TP_), sum(FP_), sum(TN_), sum(FN_)\n",
    "\n",
    "def get_accuracy_and_BER(X, y, model):\n",
    "    TP, FP, TN, FN = get_truth(X, y, model)\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "    BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "    return accuracy, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit and test on whole dataset\n",
      "Balanced Error Rate: 0.4766851431593464\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1.0, solver=\"lbfgs\")\n",
    "model.fit(X, y)\n",
    "accuracy, BER = get_accuracy_and_BER(X, y, model)\n",
    "print(\"Model fit and test on whole dataset\")\n",
    "print(\"Balanced Error Rate: {}\".format(BER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Retrain the above model using the class weight=’balanced’ option. Report the accuracy and BER of your new classifier (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit and test on whole dataset\n",
      "Balanced Error Rate: 0.304060477041619\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1.0, solver=\"lbfgs\", class_weight=\"balanced\")\n",
    "model.fit(X, y)\n",
    "accuracy, BER = get_accuracy_and_BER(X, y, model)\n",
    "print(\"Model fit and test on whole dataset\")\n",
    "print(\"Balanced Error Rate: {}\".format(BER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Shuffle the data, and split it into training, validation, and test splits, with a 50/25/25% ratio. Using the class weight=’balanced’ option, and training on the training set, report the training/validation/test accuracy and BER (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, ratio=(0.5,0.25,0.25), shuffle=True):\n",
    "    if shuffle:\n",
    "        Xy = list(zip(X,y))\n",
    "        random.shuffle(Xy)\n",
    "\n",
    "        X = [d[0] for d in Xy]\n",
    "        y = [d[1] for d in Xy]\n",
    "\n",
    "    N = len(y)\n",
    "    \n",
    "    assert len(ratio) == 3 and sum(ratio) == 1.0\n",
    "    \n",
    "    Ntrain = round(N*ratio[0])\n",
    "    Nvalid = round(N*ratio[1])\n",
    "    Ntest = round(N*ratio[2])\n",
    "\n",
    "    Xtrain, ytrain = X[:Ntrain], y[:Ntrain]\n",
    "    Xvalid, yvalid = X[Ntrain:Ntrain+Nvalid], y[Ntrain:Ntrain+Nvalid]\n",
    "    Xtest, ytest = X[Ntrain+Nvalid:], y[Ntrain+Nvalid:]\n",
    "\n",
    "    return Xtrain, Xvalid, Xtest, ytrain, yvalid, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TRAINING) Accuracy: 0.7110817941952506, BER: 0.275796342960522\n",
      "(VALIDATION) Accuracy: 0.7216358839050132, BER: 0.2887362637362638\n",
      "(TEST) Accuracy: 0.7305151915455746, BER: 0.2841127922971114\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xvalid, Xtest, ytrain, yvalid, ytest = train_val_test_split(X,y)\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=\"balanced\", solver=\"lbfgs\")\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"(TRAINING) Accuracy: {}, BER: {}\".format(*get_accuracy_and_BER(Xtrain, ytrain, model)))\n",
    "print(\"(VALIDATION) Accuracy: {}, BER: {}\".format(*get_accuracy_and_BER(Xvalid, yvalid, model)))\n",
    "print(\"(TEST) Accuracy: {}, BER: {}\".format(*get_accuracy_and_BER(Xtest, ytest, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Implement a complete regularization pipeline. Consider values of C in the range {10−4, 10−3, . . . , 103, 104}. Report (or plot) the train, validation, and test BER for each value of C. Based on these values, which classifier would you select (in terms of generalization performance) and why (1 mark)?\n",
    "\n",
    "# Not sure if plot is best here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs = [10**(-4) * 10**(x) for x in range(0, 9)]\n",
    "train_BER, valid_BER, test_BER = [], [], []\n",
    "for c in cs:\n",
    "    model = LogisticRegression(C=c, class_weight=\"balanced\", solver=\"lbfgs\")\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    train_BER.append(get_accuracy_and_BER(Xtrain,ytrain, model)[1])\n",
    "    valid_BER.append(get_accuracy_and_BER(Xvalid,yvalid, model)[1])\n",
    "    test_BER.append(get_accuracy_and_BER(Xtest,ytest, model)[1])\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(cs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8, forward=True)\n",
    "ax.bar(x - width, train_BER, width, label='Train')\n",
    "ax.bar(x, valid_BER, width, label='Valid')\n",
    "ax.bar(x + width, test_BER, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('BER')\n",
    "ax.set_title('BER Scores')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cs)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Compute the Fβ scores for β = 1, β = 0.1, and β = 10 for the above classifier, using C = 1 (on the test set) (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(beta=1) F_beta score: 0.0625\n",
      "(beta=0.1) F_beta score: 0.4391304347826087\n",
      "(beta=10) F_beta score: 0.03364423717521652\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note: In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a \n",
    "test’s accuracy. ( a type I error is detecting an effect that is not present, while a type II error is failing to \n",
    "detect an effect that is present. The terms “type I error” and “type II error” are often used interchangeably with \n",
    "the general notion of false positives and false negatives ). Fβ “measures the effectiveness of retrieval with \n",
    "respect to a user who attaches β times as much importance to recall as precision”\n",
    "\"\"\"\n",
    "def f_beta(X, y, model, beta):\n",
    "    TP, FP, TN, FN = get_truth(X, y, model)\n",
    "    return ((1 + beta**2) * TP) / (((1 + beta**2) * TP + beta**2 * FN) + FP)\n",
    "\n",
    "model = LogisticRegression(C=1.0, solver=\"lbfgs\")\n",
    "model.fit(Xtrain, ytrain)\n",
    "for beta in [1, 0.1, 10]:\n",
    "    score = f_beta(Xtest, ytest, model, beta)\n",
    "    print(\"(beta={}) F_beta score: {}\".format(beta, score))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 \n",
    "The sample weight option allows you to manually build a balanced (or imbalanced) classifier by assigning different weights to each datapoint (i.e., each label y in the training set). For example, we would assign equal weight to all samples by fitting:\n",
    "\n",
    "```\n",
    "weights = [1.0 * len(ytrain)]\n",
    "mod = linear_model.LogisticRegression(C=1, solver=’lbfgs’) mod.fit(Xtrain, ytrain, sample_weight=weights)\n",
    "```\n",
    "\n",
    "(note that you should use the lbfgs solver option, and need not set class weight=’balanced’ in\n",
    "this case). Assigning larger weights to (e.g.) positive samples would encourage the logistic regressor to\n",
    "optimize for the True Positive Rate. Using the above code, compute the Fβ score (on the test set) of your\n",
    "(unweighted) classifier, for β = 1 and β = 10. Following this, identify weight vectors that yield better\n",
    "performance (compared to the unweighted vector) in terms of the F1 and F10 scores (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
